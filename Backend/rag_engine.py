import os
from dotenv import load_dotenv
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from openai import AzureOpenAI
import json

load_dotenv()

# ==========================================
# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
# ==========================================
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
EMBEDDING_DEPLOYMENT_NAME = os.getenv("EMBEDDING_DEPLOYMENT_NAME")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_INDEX_NAME, AzureKeyCredential(AZURE_SEARCH_API_KEY))
openai_client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

# ==========================================
# 1. ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
# ==========================================
def generate_embedding(text):
    response = openai_client.embeddings.create(input=text, model=EMBEDDING_DEPLOYMENT_NAME)
    return response.data[0].embedding

# ==========================================
# 2. Azure AI Search ê²€ìƒ‰ (Retrieve)
# ==========================================
def search_documents(query, category=None, top_k=3):
    """
    category:
      - "all" ë˜ëŠ” None: styleì„ ì œì™¸í•œ ëª¨ë“  ë¬¸ì„œ ê²€ìƒ‰ (history + reference)
      - "history", "reference": í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œë§Œ ê²€ìƒ‰
    """
    try:
        # 1. ì§ˆë¬¸ ë²¡í„°í™”
        vector = generate_embedding(query)
        vector_query = VectorizedQuery(vector=vector, k_nearest_neighbors=top_k, fields="content_vector")

        # 2. í•„í„° êµ¬ì„± (OData Syntax)
        filter_str = "category ne 'style'"
        if category and category.lower() != "all":
            filter_str = f"category eq '{category}'"

        # 3. ê²€ìƒ‰ ì‹¤í–‰ (Hybrid Search)
        results = search_client.search(
            search_text=query,             # í‚¤ì›Œë“œ ê²€ìƒ‰ìš©
            vector_queries=[vector_query], # ë²¡í„° ê²€ìƒ‰ìš©
            filter=filter_str,             # ì¹´í…Œê³ ë¦¬ í•„í„°
            select=["title", "content", "created_at", "file_url", "category"],
            top=top_k
        )

        # 4. ê²°ê³¼ ì •ë¦¬
        retrieved_docs = []
        for result in results:
            category_label = result['category'].upper() if result.get('category') else "UNKNOWN"
            # ìƒì„± ë‚ ì§œë¥¼ ì½ê¸° ì‰¬ìš´ í¬ë§·ìœ¼ë¡œ ë³€í™˜ (YYYY-MM-DD)
            created_at = result.get('created_at', '')
            date_str = created_at[:10] if created_at else "ë‚ ì§œ ë¶ˆëª…"
            
            source_tag = f"[{category_label}] {result['title']} (ì‘ì„±ì¼: {date_str})"
            retrieved_docs.append(f"Source: {source_tag}\nContent: {result['content']}\n")
            
        return retrieved_docs
    
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

# ==========================================
# 3. ë‹µë³€ ìƒì„± (Generate)
# ==========================================
def generate_answer(query, context_docs):
    if not context_docs:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context_text = "\n\n".join(context_docs)
    
    system_prompt = """
    ë„ˆëŠ” ìŠ¤ë§ˆíŠ¸í•œ íšŒì˜ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
    ì•„ë˜ ì œê³µëœ [Context]ì— ìˆëŠ” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜.
    
    [ë‹µë³€ ê°€ì´ë“œ]
    1. ë¬¸ì„œì— ë‚´ìš©ì´ ìˆë‹¤ë©´ ìƒì„¸í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´.
    2. 'ì§€ë‚œ íšŒì˜', 'ìµœê·¼ íšŒì˜' ë“±ì˜ ì–¸ê¸‰ì´ ìˆìœ¼ë©´ [Context]ì˜ 'ì‘ì„±ì¼'ì„ ì°¸ê³ í•´ì„œ ê°€ì¥ ì ì ˆí•œ ì •ë³´ë¥¼ ì°¾ì•„ì¤˜.
    3. ë§Œì•½ [Context]ì— ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ì „í˜€ ì—†ë‹¤ë©´, 'ì£„ì†¡í•˜ì§€ë§Œ ê´€ë ¨ ë‚´ìš©ì„ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ì •ì¤‘íˆ ë‹µë³€í•´.
    4. ë‹µë³€ ëì—ëŠ” ë°˜ë“œì‹œ ì°¸ê³ í•œ ë¬¸ì„œì˜ [ì œëª©]ê³¼ (ì‘ì„±ì¼)ì„ ì¸ìš©í•´ì¤˜.
    """
    
    user_prompt = f"""
    [Context]
    {context_text}

    [Question]
    {query}
    """

    response = openai_client.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT_NAME,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )

    return response.choices[0].message.content

# ==========================================
# 4. íšŒì˜ ë¶„ì„ (Analyze Meeting)
# ==========================================
def analyze_meeting_script(transcript):
    """
    íšŒì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìš”ì•½, ê²°ì •ì‚¬í•­, í•  ì¼ ë“±ì„ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë°˜í™˜
    """
    prompt = f"""
    ë‹¹ì‹ ì€ íšŒì˜ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [íšŒì˜ ìŠ¤í¬ë¦½íŠ¸]ë¥¼ ì½ê³  ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
    ë°˜ë“œì‹œ ë‹¤ìŒ í‚¤ë¥¼ ê°€ì§„ JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

    JSON Keys:
    - summary: íšŒì˜ ì „ì²´ì˜ í•µì‹¬ ë‚´ìš©ì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
    - decisions: íšŒì˜ì—ì„œ í•©ì˜ëœ ì£¼ìš” ê²°ì •ì‚¬í•­ ëª©ë¡ (ë¬¸ìì—´ ë°°ì—´)
    - actionItems: [ {{"task": "í•  ì¼", "assignee": "ë‹´ë‹¹ì", "deadline": "YYYY-MM-DD" }} ] í˜•ì‹ì˜ ë°°ì—´
    - openIssues: ì•„ì§ ê²°ë¡ ë‚˜ì§€ ì•Šì€ ë¯¸í•´ê²° ì•ˆê±´ ëª©ë¡ (ë¬¸ìì—´ ë°°ì—´)
    - followUpMeeting: {{ "title": "íšŒì˜ëª…", "date": "YYYY-MM-DD", "time": "HH:MM", "attendees": [] }} ì˜¤ë¸Œì íŠ¸
    - insights: {{ "meetingType": "íšŒì˜ìœ í˜•", "sentiment": "ë¶„ìœ„ê¸°(ê¸ì •/ë¶€ì •/ì¤‘ë¦½)", "keyTopics": [], "risks": [ {{ "level": "high/medium/low", "description": "ìœ„í—˜ ìš”ì†Œ ë‚´ìš©" }} ], "recommendations": [] }}

    [íšŒì˜ ìŠ¤í¬ë¦½íŠ¸]
    {transcript}
    """

    response = openai_client.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT_NAME,
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ìœ ëŠ¥í•œ ë¹„ì„œì•¼. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´."},
            {"role": "user", "content": prompt}
        ],
        response_format={"type": "json_object"}
    )

    result = json.loads(response.choices[0].message.content)
    return result

# ==========================================
# ë©”ì¸ í•¨ìˆ˜ (ì™¸ë¶€ í˜¸ì¶œìš©)
# ==========================================
def ask_bot(user_query, target_category="history"):
# ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
    print(f"ğŸ” ê²€ìƒ‰ ì¤‘... (Category: {target_category})")
    
    # 1. ê²€ìƒ‰
    docs = search_documents(user_query, category=target_category)
    
    # 2. ë‹µë³€ ìƒì„±
    answer = generate_answer(user_query, docs)
    
    return answer

# ==========================================
# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ==========================================
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    q = "ê·¸ ì—¬í–‰ì‚¬ ì´ë¦„ì´ ë­ì˜€ì§€?"
    
    # history ì¹´í…Œê³ ë¦¬ì—ì„œ ê²€ìƒ‰
    response = ask_bot(q, target_category="history")
    
    print("\nğŸ¤– AI ë‹µë³€:")
    print(response)