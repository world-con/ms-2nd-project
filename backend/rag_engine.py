import os
from dotenv import load_dotenv
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from openai import AzureOpenAI

load_dotenv()

# ==========================================
# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
# ==========================================
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
AZURE_OPENAI_DEPLOYMENT_NAME = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
EMBEDDING_DEPLOYMENT_NAME = os.getenv("EMBEDDING_DEPLOYMENT_NAME")

# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_INDEX_NAME, AzureKeyCredential(AZURE_SEARCH_API_KEY))
openai_client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

# ==========================================
# 1. ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
# ==========================================
def generate_embedding(text):
    response = openai_client.embeddings.create(input=text, model=EMBEDDING_DEPLOYMENT_NAME)
    return response.data[0].embedding

# ==========================================
# 2. Azure AI Search ê²€ìƒ‰ (Retrieve)
# ==========================================
def search_documents(query, category=None, top_k=3):
    """
    category:
      - "all" ë˜ëŠ” None: styleì„ ì œì™¸í•œ ëª¨ë“  ë¬¸ì„œ ê²€ìƒ‰ (history + reference)
      - "history", "reference": í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œë§Œ ê²€ìƒ‰
    """
    try:
        # 1. ì§ˆë¬¸ ë²¡í„°í™”
        vector = generate_embedding(query)
        vector_query = VectorizedQuery(vector=vector, k_nearest_neighbors=top_k, fields="content_vector")

        # 2. í•„í„° êµ¬ì„± (OData Syntax)
        filter_str = "category ne 'style'"
        if category and category.lower() != "all":
            filter_str = f"category eq '{category}'"

        # 3. ê²€ìƒ‰ ì‹¤í–‰ (Hybrid Search)
        results = search_client.search(
            search_text=query,             # í‚¤ì›Œë“œ ê²€ìƒ‰ìš©
            vector_queries=[vector_query], # ë²¡í„° ê²€ìƒ‰ìš©
            filter=filter_str,             # ì¹´í…Œê³ ë¦¬ í•„í„°
            select=["title", "content", "created_at", "file_url", "category"],
            top=top_k
        )

        # 4. ê²°ê³¼ ì •ë¦¬
        retrieved_docs = []
        for result in results:
            source_tag = f"[{result['category'].upper()}] {result['title']}"
            retrieved_docs.append(f"Source: {source_tag}\nContent: {result['content']}\n")
            
        return retrieved_docs
    
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

# ==========================================
# 3. ë‹µë³€ ìƒì„± (Generate)
# ==========================================
def generate_answer(query, context_docs):
    if not context_docs:
        return "ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context_text = "\n\n".join(context_docs)
    
    system_prompt = """
    ë„ˆëŠ” íšŒì˜ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼.
    ì•„ë˜ ì œê³µëœ [Context]ì— ìˆëŠ” ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´.
    ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ê³  'ë¬¸ì„œì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§í•´.
    ë‹µë³€ ëì—ëŠ” ì°¸ê³ í•œ ë¬¸ì„œì˜ ì œëª©ì„ ì¸ìš©í•´.
    """
    
    user_prompt = f"""
    [Context]
    {context_text}

    [Question]
    {query}
    """

    response = openai_client.chat.completions.create(
        model=AZURE_OPENAI_DEPLOYMENT_NAME,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
    )

    return response.choices[0].message.content

# ==========================================
# ë©”ì¸ í•¨ìˆ˜ (ì™¸ë¶€ í˜¸ì¶œìš©)
# ==========================================
def ask_bot(user_query, target_category="history"):
    print(f"ğŸ” ê²€ìƒ‰ ì¤‘... (Category: {target_category})")
    
    # 1. ê²€ìƒ‰
    docs = search_documents(user_query, category=target_category)
    
    # 2. ë‹µë³€ ìƒì„±
    answer = generate_answer(user_query, docs)
    
    return answer

# ==========================================
# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ==========================================
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    q = "ê·¸ ì—¬í–‰ì‚¬ ì´ë¦„ì´ ë­ì˜€ì§€?"
    
    # history ì¹´í…Œê³ ë¦¬ì—ì„œ ê²€ìƒ‰
    response = ask_bot(q, target_category="history")
    
    print("\nğŸ¤– AI ë‹µë³€:")
    print(response)