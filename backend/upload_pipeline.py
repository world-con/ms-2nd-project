# pip install azure-core azure-storage-blob azure-search-documents openai pypdf python-docx python-dotenv

import os
from dotenv import load_dotenv
import base64
from datetime import datetime, timezone
from pypdf import PdfReader
from docx import Document
from azure.core.credentials import AzureKeyCredential
from azure.storage.blob import BlobServiceClient
from azure.search.documents import SearchClient
from openai import AzureOpenAI

load_dotenv()

# ==========================================
# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
# ==========================================
BLOB_CONNECTION_STRING = os.getenv("BLOB_CONNECTION_STRING")
AZURE_SEARCH_ENDPOINT = os.getenv("AZURE_SEARCH_ENDPOINT")
AZURE_SEARCH_API_KEY = os.getenv("AZURE_SEARCH_API_KEY")
AZURE_SEARCH_INDEX_NAME = os.getenv("AZURE_SEARCH_INDEX_NAME")

AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_API_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
EMBEDDING_DEPLOYMENT_NAME = os.getenv("EMBEDDING_DEPLOYMENT_NAME")

# ==========================================
# í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ==========================================
blob_service_client = BlobServiceClient.from_connection_string(BLOB_CONNECTION_STRING)
search_client = SearchClient(AZURE_SEARCH_ENDPOINT, AZURE_SEARCH_INDEX_NAME, AzureKeyCredential(AZURE_SEARCH_API_KEY))
openai_client = AzureOpenAI(
    api_key=AZURE_OPENAI_API_KEY,
    api_version=AZURE_OPENAI_API_VERSION,
    azure_endpoint=AZURE_OPENAI_ENDPOINT
)

# ==========================================
# 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
# ==========================================
def extract_text_from_file(file_path):
    ext = os.path.splitext(file_path)[1].lower()
    text = ""
    
    if ext == ".pdf":
        from pypdf import PdfReader
        try:
            reader = PdfReader(file_path)
            for page in reader.pages:
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"
        except Exception as e:
            print(f"PDF extract error: {e}")

    elif ext == ".docx":     
        try:
            doc = Document(file_path)
            for element in doc.element.body:
                # ë¬¸ë‹¨(Paragraph)
                if element.tag.endswith('p'):
                    # XML elementì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•´ paragraph ê°ì²´ë¡œ ë˜í•‘
                    # (ê°„ë‹¨íˆ doc.paragraphsì—ì„œ ì°¾ëŠ” ëŒ€ì‹  element textë¥¼ ì§ì ‘ ê°€ì ¸ì˜´)
                    para_text = "".join([node.text for node in element.iter() if node.text])
                    if para_text.strip():
                        text += para_text + "\n"
                
                # í‘œ(Table) -> Markdown í¬ë§·ìœ¼ë¡œ ë³€í™˜
                elif element.tag.endswith('tbl'):
                    # í‘œ ì²˜ë¦¬ë¥¼ ìœ„í•´ Document ê°ì²´ ë‚´ì˜ í•´ë‹¹ í…Œì´ë¸” ì¸ë±ìŠ¤ë¥¼ ì°¾ê±°ë‚˜
                    # ê°„ë‹¨íˆ í…ìŠ¤íŠ¸ë§Œ ê¸ì–´ëª¨ì€ í›„ elementë¥¼ ìˆœíšŒí•˜ë©° ì…€ ë°ì´í„°ë¥¼ '|'ë¡œ ë¬¶ê¸°
                    
                    table_text = []
                    # í–‰(Row) ìˆœíšŒ
                    for row in element.findall('.//{http://schemas.openxmlformats.org/wordprocessingml/2006/main}tr'):
                        row_cells = []
                        # ì—´(Cell) ìˆœíšŒ
                        for cell in row.findall('.//{http://schemas.openxmlformats.org/wordprocessingml/2006/main}tc'):
                            # ì…€ ë‚´ë¶€ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì…€ ì•ˆì—ë„ ë¬¸ë‹¨ì´ ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆìŒ)
                            cell_content = "".join([node.text for node in cell.iter() if node.text]).strip()
                            row_cells.append(cell_content)
                        
                        # Markdown í–‰ ìƒì„±: | ê°’1 | ê°’2 | ê°’3 |
                        if row_cells:
                            table_text.append("| " + " | ".join(row_cells) + " |")
                    
                    if table_text:
                        text += "\n" + "\n".join(table_text) + "\n\n"
        except Exception as e:
            print(f"DOCX extract error: {e}")
    
    else:
        # .txt ë“± ê¸°íƒ€ íŒŒì¼ ì§€ì›
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()
            
    return text

# ==========================================
# 2. ì²­í‚¹ (Chunking)
# ==========================================
def chunk_text(text, chunk_size=1000, overlap=100):
    """
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ chunk_size ê¸¸ì´ë¡œ ìë¥´ë˜, 
    ë¬¸ë§¥ ë‹¨ì ˆì„ ë§‰ê¸° ìœ„í•´ overlap ë§Œí¼ ê²¹ì¹˜ê²Œ ìë¦…ë‹ˆë‹¤.
    """
    chunks = []
    start = 0
    text_len = len(text)
    
    while start < text_len:
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        # ê²¹ì¹˜ê²Œ ì´ë™ (ë‹¤ìŒ ì‹œì‘ì ì€ í˜„ì¬ ëì  - overlap)
        start += (chunk_size - overlap)
        
    return chunks

# ==========================================
# 3. ì„ë² ë”© ìƒì„± (Vectorize)
# ==========================================
def generate_embedding(text):
    response = openai_client.embeddings.create(
        input=text,
        model=EMBEDDING_DEPLOYMENT_NAME
    )
    return response.data[0].embedding

# ==========================================
# 4. ID ì¸ì½”ë”© (Base64)
# ==========================================
def encode_id(raw_id):
    # Azure Search IDëŠ” URL-safe ë¬¸ìë§Œ í—ˆìš©í•˜ë¯€ë¡œ Base64 ì¸ì½”ë”© í•„ìˆ˜
    return base64.urlsafe_b64encode(raw_id.encode()).decode()

# ==========================================
# [ë©”ì¸ ë¡œì§] íŒŒì¼ ì—…ë¡œë“œ ë° ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸
# ==========================================
def upload_file_to_rag(file_path, category, container_name="default"):
    """
    file_path: ë¡œì»¬ íŒŒì¼ ê²½ë¡œ
    category: 'history', 'reference', 'style' ì¤‘ í•˜ë‚˜
    container_name: Blob ì»¨í…Œì´ë„ˆ ì´ë¦„ (history, reference, style)
    """
    filename = os.path.basename(file_path)
    print(f"ğŸš€ ì²˜ë¦¬ ì‹œì‘: {filename} (Category: {category})")

    # 1. Blob Storageì— íŒŒì¼ ì—…ë¡œë“œ
    try:
        # ì»¨í…Œì´ë„ˆê°€ ì—†ìœ¼ë©´ ìƒì„±
        container_client = blob_service_client.get_container_client(container_name)
        if not container_client.exists():
            container_client.create_container()
            
        blob_client = container_client.get_blob_client(filename)
        
        with open(file_path, "rb") as data:
            blob_client.upload_blob(data, overwrite=True)
            
        file_url = blob_client.url
        print(f"   [1/4] Blob ì—…ë¡œë“œ ì™„ë£Œ: {file_url}")
        
    except Exception as e:
        print(f"âŒ Blob ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    # 2. íŒŒì¼ ìš©ëŸ‰ ê³„ì‚°
    def get_readable_file_size(file_path):
        size_bytes = os.path.getsize(file_path)
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024

    file_size_str = get_readable_file_size(file_path)

    # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹
    full_text = extract_text_from_file(file_path)
    chunks = chunk_text(full_text)
    print(f"   [2/4] í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹ ì™„ë£Œ ({len(chunks)}ê°œ ì²­í¬)")

    # 4. ì„ë² ë”© ìƒì„± ë° ë¬¸ì„œ ê°ì²´ ìƒì„±
    search_documents = []
    for i, chunk in enumerate(chunks):
        # ê° ì²­í¬ë§ˆë‹¤ ê³ ìœ  ID ìƒì„± (íŒŒì¼ URL + ì²­í¬ë²ˆí˜¸)
        # ì˜ˆ: https://.../file.pdf_0, https://.../file.pdf_1
        chunk_id = f"{file_url}_{i}"
        encoded_id = encode_id(chunk_id)
        
        vector = generate_embedding(chunk)

        # í˜„ì¬ ì‹œê°„ì„ UTC ê¸°ì¤€ ISO 8601 ë¬¸ìì—´ë¡œ ìƒì„± (ì˜ˆ: '2025-12-29T05:23:11.123456+00:00' í˜•íƒœ)
        current_time_str = datetime.now(timezone.utc).isoformat()
        
        doc = {
            "id": encoded_id,
            "title": filename,
            "content": chunk,
            "category": category,
            "file_url": file_url,
            "content_vector": vector,
            "created_at": current_time_str,
            "size": file_size_str
        }
        search_documents.append(doc)
        
    print(f"   [3/4] ì„ë² ë”© ìƒì„± ì™„ë£Œ")

    # 5. Azure AI Searchì— ì—…ë¡œë“œ
    try:
        # ë°°ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í•œ ë²ˆì— ì—…ë¡œë“œ (íš¨ìœ¨ì„±)
        result = search_client.upload_documents(documents=search_documents)
        print(f"   [4/4] ì¸ë±ì‹± ì™„ë£Œ! (ì„±ê³µ: {len(result)})")
        print(f"âœ… ìµœì¢… ì™„ë£Œ: {filename}")
        
    except Exception as e:
        print(f"âŒ ì¸ë±ì‹± ì‹¤íŒ¨: {e}")

# ==========================================
# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ==========================================
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ê²½ë¡œ
    sample_file = "TEST_PDF/Margies Travel Company Info_ko.pdf"
    
    # ì˜ˆì‹œ: ê³¼ê±° íšŒì˜ë¡(History) ì—…ë¡œë“œ
    # íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ í›„ ì‹¤í–‰
    if os.path.exists(sample_file):
        upload_file_to_rag(
            file_path=sample_file, 
            category="history", 
            container_name="history"
        )
    else:
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {sample_file}")