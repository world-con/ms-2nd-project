import React, { createContext, useContext, useState, useRef, useEffect } from 'react'
import axios from 'axios';

const AppContext = createContext()
const WHISPER_BACKEND_URL = import.meta.env.VITE_WHISPER_BACKEND_URL || "https://ieum-stt.livelymushroom-0e97085f.australiaeast.azurecontainerapps.io";
const WHISPER_WS_URL = import.meta.env.VITE_WHISPER_WS_URL || "wss://ieum-stt.livelymushroom-0e97085f.australiaeast.azurecontainerapps.io/ws";

export const useAppContext = () => {
  const context = useContext(AppContext)
  if (!context) {
    throw new Error('useAppContext must be used within AppProvider')
  }
  return context
}

export const AppProvider = ({ children }) => {
  const [isLoggedIn, setIsLoggedIn] = useState(false)
  const [currentMeeting, setCurrentMeeting] = useState(null)
  const [meetings, setMeetings] = useState([])

  // íšŒì˜ ìƒíƒœ ì „ì—­ ê´€ë¦¬
  const [isRecording, setIsRecording] = useState(false)
  const [isPaused, setIsPaused] = useState(false)
  const [recordingTime, setRecordingTime] = useState(0)
  const [flowState, setFlowState] = useState("idle") // 'idle' | 'registration' | 'recording' | 'saving' | 'completed'
  const [backendStatus, setBackendStatus] = useState("disconnected")
  const [transcript, setTranscript] = useState("")
  const [realtimeSegments, setRealtimeSegments] = useState([])
  const [registeredSpeakers, setRegisteredSpeakers] = useState([]) // [NEW] ë“±ë¡ ì™„ë£Œëœ í™”ìž ëª©ë¡
  const [pendingRegistrations, setPendingRegistrations] = useState([]) // [NEW] ì„œë²„ ì—°ê²° ì „ ìž„ì‹œ ë³´ê´€í•¨
  const [aiSummary, setAiSummary] = useState("")

  const [aiMessages, setAiMessages] = useState([
    { type: "ai", text: "íšŒì˜ ì¤‘ ê¶ê¸ˆí•œ ì ì´ ìžˆìœ¼ë©´ ë¬¼ì–´ë³´ì„¸ìš”!", time: new Date().toLocaleTimeString("ko-KR", { hour: "2-digit", minute: "2-digit" }) },
  ]);

  // ë¡œì§ìš© Ref
  const mediaRecorderRef = useRef(null);
  const socketRef = useRef(null);
  const chunkIndexRef = useRef(0);
  const chunkTimerRef = useRef(null);
  const recordingTimerRef = useRef(null);
  const isRecordingRef = useRef(false); // [v8.2] onstop ì œì–´ìš©
  const isPausedRef = useRef(false);    // [v8.2] onstop ì œì–´ìš©

  // 1. ë°±ì—”ë“œ ì˜ˆì—´ & ì†Œì¼“ ì—°ê²° (ë¡œê·¸ì¸ ì‹œ ë˜ëŠ” ì•± ì‹œìž‘ ì‹œ)
  useEffect(() => {
    let reconnectTimer;
    const warmupAndConnect = async () => {
      try {
        setBackendStatus("loading");
        await axios.get(`${WHISPER_BACKEND_URL}/status`, { timeout: 10000 });
        connectSocket();
      } catch (e) {
        console.log("ðŸ“¡ Backend startup check failed, retrying socket...");
        connectSocket();
      }
    };

    const connectSocket = () => {
      if (socketRef.current?.readyState === WebSocket.OPEN) return;
      const socket = new WebSocket(WHISPER_WS_URL);
      socket.onopen = () => setBackendStatus("connected");
      socket.onmessage = (event) => {
        const data = JSON.parse(event.data);
        if (data.type === "status") setBackendStatus(data.value);
        if (data.type === "new_segments") {
          // [í•µì‹¬] ë°±ì—”ë“œì—ì„œ ì˜¨ í™”ìž ë¶„ë¦¬ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëˆ„ì 
          setRealtimeSegments((prev) => [...prev, ...data.segments]);
        }
      };

      socket.onclose = () => {
        setBackendStatus("disconnected");
        reconnectTimer = setTimeout(connectSocket, 5000);
      };
      socketRef.current = socket;
    };

    warmupAndConnect();
    return () => {
      clearTimeout(reconnectTimer);
    };
  }, []);

  // [NEW] ì„œë²„ ì—°ê²° ì‹œ ì˜ˆì•½ëœ í™”ìž ë“±ë¡ ìžë™ ì „ì†¡
  useEffect(() => {
    if (backendStatus === "connected" && pendingRegistrations.length > 0) {
      const flushRegistrations = async () => {
        console.log("ðŸš€ Flushing pending registrations...");
        for (const reg of pendingRegistrations) {
          try {
            await handleRegisterSpeaker(reg.name, reg.email, reg.blob);
            // ì„±ê³µ ì‹œ pendingì—ì„œ ì œê±°ëŠ” ë§ˆì§€ë§‰ì— ì¼ê´„ ì²˜ë¦¬í•˜ê±°ë‚˜ ê°œë³„ ì²˜ë¦¬
          } catch (e) {
            console.error("Flush failed for", reg.name, e);
          }
        }
        setPendingRegistrations([]); // ì „ì†¡ ì‹œë„ í›„ í ì´ˆê¸°í™”
      };
      flushRegistrations();
    }
  }, [backendStatus, pendingRegistrations.length]);

  // 2. íƒ€ì´ë¨¸ ë¡œì§ (ê¸°ë³¸ ë…¹ìŒ ì‹œê°„ & 30ì´ˆ ë‹¨ìœ„ ë°ì´í„° ìš”ì²­)
  useEffect(() => {
    if (isRecording && !isPaused) {
      // (1) ì „ì²´ ë…¹ìŒ ì‹œê°„ íƒ€ì´ë¨¸
      recordingTimerRef.current = setInterval(() => {
        setRecordingTime((prev) => prev + 1);
      }, 1000);

      // (2) [v8] 30ì´ˆë§ˆë‹¤ ë°ì´í„°(requestData) ìš”ì²­ íƒ€ì´ë¨¸
      // ì´ì „ì— 'stale closure' ë¬¸ì œê°€ ìžˆë˜ setIntervalì„ ì—¬ê¸°ë¡œ ì˜®ê²¼ìŠµë‹ˆë‹¤.
      chunkTimerRef.current = setInterval(() => {
        if (mediaRecorderRef.current?.state === "recording") {
          // [v8.2] requestData() ëŒ€ì‹  stop() í˜¸ì¶œ -> onstopì—ì„œ ìƒˆ ë…ë¦½ íŒŒì¼ ìƒì„±
          mediaRecorderRef.current.stop();
        }
      }, 30000);
    } else {
      clearInterval(recordingTimerRef.current);
      clearInterval(chunkTimerRef.current);
    }
    return () => {
      clearInterval(recordingTimerRef.current);
      clearInterval(chunkTimerRef.current);
    };
  }, [isRecording, isPaused]);


  // 3. ì²­í¬ ì—…ë¡œë“œ ë¡œì§
  const uploadChunk = async (blob) => {
    const currentIndex = chunkIndexRef.current;
    chunkIndexRef.current += 1;
    const formData = new FormData();
    formData.append("chunkIndex", currentIndex);
    formData.append("file", blob, `chunk_${currentIndex}.webm`);
    try {
      await axios.post(`${WHISPER_BACKEND_URL}/chunk`, formData);
    } catch (e) { console.error("Chunk upload fail", e); }
  };

  // 4. ì•¡ì…˜ í•¸ë“¤ëŸ¬
  const handleStartMeetingFlow = () => {
    // [NEW] ë°”ë¡œ ë…¹ìŒ ì•ˆ í•˜ê³  ë“±ë¡ ë‹¨ê³„ë¡œ ì§„ìž…
    setFlowState("registration");
  };

  const handleRegisterSpeaker = async (name, email, audioBlob) => {
    const formData = new FormData();
    formData.append("name", name);
    formData.append("email", email || "");
    formData.append("consent", "true");
    formData.append("file", audioBlob, "registration.webm");

    // ì„œë²„ê°€ ì•„ì§ ì—°ê²° ì „ì´ë¼ë©´ íì— ë‹´ê¸°ë§Œ í•¨
    if (backendStatus !== "connected") {
      setPendingRegistrations(prev => [...prev, { name, email, blob: audioBlob }]);
      return { status: "queued" };
    }

    try {
      const resp = await axios.post(`${WHISPER_BACKEND_URL}/register_speaker`, formData);
      setRegisteredSpeakers((prev) => [...prev, name]);
      return resp.data;
    } catch (e) {
      console.error("Speaker registration fail", e);
      throw e;
    }
  };

  const handleStartRecording = () => {
    navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
      const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) uploadChunk(e.data);
      };

      // [v8.2] Stop-Restart í•µì‹¬: ë©ˆì·„ì„ ë•Œ ë…¹ìŒ ìƒíƒœë¼ë©´ ì¦‰ì‹œ ë‹¤ì‹œ ì‹œìž‘
      mediaRecorder.onstop = () => {
        if (isRecordingRef.current && !isPausedRef.current) {
          mediaRecorder.start();
        }
      };

      mediaRecorder.start();
      mediaRecorderRef.current = mediaRecorder;
      setIsRecording(true);
      isRecordingRef.current = true; // Refë¡œ ì¦‰ì‹œ ìƒíƒœ ê´€ë¦¬ (onstop ëŒ€ì‘)
      setFlowState("recording");
      setRecordingTime(0);

    }).catch(err => {
      alert("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
      setFlowState("idle");
    });
  };

  const handlePauseResume = () => {
    if (!mediaRecorderRef.current) return;

    if (mediaRecorderRef.current.state === "recording") {
      // ì¼ì‹œì •ì§€ ì§ì „ í˜„ìž¬ê¹Œì§€ ë…¹ìŒëœ ë°ì´í„°ë¥¼ ê°•ì œë¡œ ì „ì†¡ (Stop-Restart ì „ëžµì— ë§žì¶¤)
      mediaRecorderRef.current.stop();
      setIsPaused(true);
      isPausedRef.current = true;
    } else if (mediaRecorderRef.current.state === "paused") {
      mediaRecorderRef.current.resume();
      setIsPaused(false);
      isPausedRef.current = false;
    }
  };


  const handleStopRecordingFlow = async () => {
    setIsRecording(false);
    isRecordingRef.current = false;
    setFlowState("saving");
    if (mediaRecorderRef.current?.state !== "inactive") {
      mediaRecorderRef.current.stop();
    }
    clearInterval(chunkTimerRef.current);
    try {
      const resp = await axios.post(`${WHISPER_BACKEND_URL}/end`);
      setTranscript(`íšŒì˜ ì €ìž¥ ì™„ë£Œ (ì„¸ê·¸ë¨¼íŠ¸: ${resp.data.segments || 0})`);
      setFlowState("completed");
    } catch (e) { setFlowState("completed"); }
  };

  const handleResetMeeting = async () => {
    try {
      await axios.post(`${WHISPER_BACKEND_URL}/reset`);
      setFlowState("idle");
      setRecordingTime(0);
      setTranscript("");
      setRealtimeSegments([]); // ì‹¤ì‹œê°„ ë°ì´í„°ë„ ì´ˆê¸°í™”
    } catch (e) { setFlowState("idle"); }

  };

  const startMeeting = (meetingData) => {
    setCurrentMeeting(meetingData);
    setFlowState("idle");
    setRecordingTime(0);
    setTranscript("");
    setAiSummary("");
  };

  const value = {
    isLoggedIn, setIsLoggedIn,
    currentMeeting, setCurrentMeeting,
    meetings, setMeetings,
    isRecording, setIsRecording,
    isPaused, setIsPaused,
    recordingTime, setRecordingTime,
    flowState, setFlowState,
    backendStatus, setBackendStatus,
    transcript, setTranscript,
    aiSummary, setAiSummary,
    aiMessages, setAiMessages,
    handleStartRecording,
    handlePauseResume,
    handleStopRecordingFlow,
    handleResetMeeting,
    startMeeting,
    realtimeSegments, setRealtimeSegments,
    handleStartMeetingFlow,
    handleRegisterSpeaker,
    registeredSpeakers, setRegisteredSpeakers,
    pendingRegistrations, // ë…¸ì¶œ
  }


  return <AppContext.Provider value={value}>{children}</AppContext.Provider>
}
